# Deeplearning_Coursea
2021 하계 딥러닝

Neuro Network

- 어떤 2차원 이상의 데이터셋을 수학적 함수(= System)로 모델링하였다고 하자. (집의 크기와 가격 곡선)
- 이것은 신호및시스템 과목에서 배웠던 어떤 Linear 한 시스템의 형태로 나타날 것이다.


- 이러한 하나의 작은 수학적 시스템 하나가 바로 뉴런 Neuron 이다.
- 이러한 뉴런들이 무수히 많이 중첩되어 생긴 것이 신경망이다. 생물학적으로도, 컴퓨터과학적으로도 그렇다.

+ 위의 집값은 음으로 내려가지 않으므로, 직선은 한 위치에서 꺾이게 되어 있다.
+ 이러한 꺾인 직선형의 개형을 Rectified Linear Units 라고 부른다.



집값 문제 - Complex

- 사실 집값은 훨씬 더 많은 요소들에 의해 결정된다.
- 가장 얕은 input 으로 우편번호(한남동의 우편번호는 더 높은 집값을 위한 가중치가 될 수 있다), 크기, 인근 집값, 방의 개수 등이 있겠다.

- 이런 '구체적인' 값 들은 조금 더 '추상적인' 수치들로 변환된다(ex:산책의 용이함, 학군)
- 그리고 이렇게 추정된 추상적인 수치들(말하자면 삶의 질)이 한번 더 system 을 거쳐 Price 를 결정하게 되는 것이다.

- 이때 가장 구체적이었던 데이터들이 바로 input Vector 가 될 것이다.
- 이들은 한 'Layer'(아마도 중간 System)를 거쳐 추상적인 데이터들로 변환되며
- 추상적인 데이터들이 또한번 계산된 다음 Layer 가 최종 값인 Price 가 되겠다.

- 여기서 Remarkable 한 것은, 사용자가 할 일은 Input Vector 를 입력하는 것 뿐이라는 사실이다.
- 중간 단계의 추상적인 값 들은, 이전 Layer 로부터 적절하게 넘겨받은 값들을 알아서 계산한다. 그리고 Price 를 얻어낸다.
- 개발자가 할 일은, 이러한 Layer 들을 지나는 수학적 모델을 긴밀하게 설계하여 최종 값에 이르는 Neuro Network 를 만들어내는 게 될 것이다.



여러 네트워크 모델들

- Standard NN : 위의 집값모델과 같은. Linear 한 Node 들의 연결 스러운? 신경망.
- Convolution NN : 컨볼루션을 사용한 신경망 - Image 가공에서 많이 사용
- Recursive NN : 재귀를 사용한 신경망 - 주로 오디오 등의 연속적인 데이터를 다룰때 많이 사용





Structured Data & Unstructured Data 

Structured Data : Feature 들의 의미 등이 선제적으로 정의된 상태로 주어진다.
Unstructured Data : 이미지의 픽셀들, 오디오의 값들 등 말그대로 구조화되지 않은 데이터들이다.

- 기업 등에서 어떤 수학적 데이터를 예측하거나 광고의 수요를 예측하기 위해 사용하는, 주로 대규모의 데이터 사용은 Structured 형태로 이루어진다.
ㄴ> 아마 자본주의적인 가치는 이쪽이 좀더 빼어나지 않을까? 더 구조화 되어있을 수록 대규모로 체계적으로 다루기 좋지 않을까 싶은 생각이다.

- 사실 Unstructured 는 인간이 진화하면서 좀 더 잘 하도록 발달한 측면이라 상대적으로 최근에 성장하였다.




이쪽 분야가 최근 급부상하는 이유

- 초기에는 이 기술의 활용이 광고예측, 이메일 Sort 영역에서의 활용에 그쳤다.
- 이 시기에는 데이터가 아무리 많이 쌓여도 퍼포먼스가 증가할 여지가 없었다. 


- 그런데 최근 20년에 들어서는, 스마트폰, 컴퓨터 등의 보급으로 인해 쌓이는 데이터의 양의 규모가 크게 증가하였다.
- 데이터의 양 자체도 증가하였고, 더 큰 신경망 모델링도 수학적으로 개발되기 시작하였다.
- 모델이 낼 수 있는 퍼포먼스의 한계점과 물리적인 데이터의 양이 동시에 증가한 것이다.

- 그래서 결과적으로, 이메일이나 분류하던 이 기술이 알파고같은 바둑 세계 챔피언을 배출해내는 지경에 이르게 된 것이다.


+ 소문자 m 은 앞으로 이 강의에서 Training Set 의 수를 설명하게 될 것이다.
+ 어떤 모델은 그 한계지점이 낮은 대신, 적은 데이터만 주어졌다는 전제 하에 학습의 속도 자체는 더 대규모의 Complex 알고리즘보다 더 빠를 수 있다.


알고리즘의 중요성

- 시간이 지날수록 하드웨어 차원에서 학습 속도가 빨라지고 있다.
- 하지만 좋은 알고리즘 역시 학습 속도를 빠르게 할 수 있다.
- 개발자는 좋은 알고리즘의 개발을 통해 학습 속도를 늘리려는 시도를 할 수 있다.

- 학습의 사이클이 있다.  
- Idea -> Code -> Experiment -> 개선된 Idea 가 그것이다.
- 느린 학습속도는 위의 Positive Feedback 의 회전속도를 직관적으로 느리게 만든다. 따라서 좋은 학습속도를 확보하도록 하자




+ 이 강의는 총 5개의 강의로 구성된 코스들 중 첫번째를 차지하고 있다.


