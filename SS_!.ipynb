{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167fa5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78668e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1,2,3,4,5]\n",
    "y_data = [1,2,3,4,5]\n",
    "\n",
    "#W 와 b 의 자료구조도 tf 내부의 객체인 것을 확인할 수 있다\n",
    "W = tf.Variable(2.9)\n",
    "b = tf.Variable(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32f10550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0|    2.1100|    0.2814| 26.608435\n",
      "   10|    1.0806| -0.002888|  0.120284\n",
      "   20|    1.0113|  -0.02127|  0.000637\n",
      "   30|    1.0064|   -0.0218|  0.000090\n",
      "   40|    1.0059|  -0.02116|  0.000082\n",
      "   50|    1.0057|  -0.02046|  0.000077\n",
      "   60|    1.0055|  -0.01978|  0.000072\n",
      "   70|    1.0053|  -0.01912|  0.000067\n",
      "   80|    1.0051|  -0.01848|  0.000063\n",
      "   90|    1.0049|  -0.01787|  0.000058\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "#보통 with 구문과 함께 쓰이는 Gradient Tape\n",
    "#변수들의 변화에 대한 정보가 tape 객체에 기록되고 있다\n",
    "#tape 의 gradient 객체를 호출하여 경사값 = 미분값을 구한다.\n",
    "#변수들에 대한 개별 미분값이 튜플 형태로 반환된다. \n",
    "\n",
    "for i in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = hypothesis= W * x_data + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "    \n",
    "    #아래 행의 return 은 cost 에 대한 W,b 의 미분이다.\n",
    "    #좌변에 있는 두 변수에 각각 할당이 된다.\n",
    "    W_grad, b_grad = tape.gradient(cost,[W,b])\n",
    "\n",
    "\n",
    "    #W 와 b 가 업데이트 되고 있다. C/C++ 의 '-=' 와 같다.\n",
    "    #텐서의 메서드를 직접 호출하여 사용한다. \n",
    "    #learing rate 로 하여 감쇠 또는 증폭되는 양이 조절되고 있다.\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    #Dataset x_data 는 5차원 데이타이다. y 역시 5차원.\n",
    "    #이 한 짝의 데이터셋에 대해서만 학습이 이루어진다.\n",
    "    #코세라에서는 m 개의 데이터셋에 대한 평균을 산출했었다.\n",
    "    \n",
    "    #\n",
    "    \n",
    "    #출력 시퀀스\n",
    "    if i%10 ==0:\n",
    "        print(\"{:5}|{:10.4f}|{:10.4}|{:10.6f}\".format(i,W.numpy(), b.numpy(),cost))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
